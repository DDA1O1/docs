---
title: "Docker Containers: An Overview"
description: "Learn about Docker containers, their evolution from raw servers and VMs, how they compare, and how to install Docker."
---

import { Aside, Steps } from '@astrojs/starlight/components';

## The Evolution of Application Deployment

Understanding Docker containers starts with understanding the problems they solve, evolving from older infrastructure models.

### 1. Raw Servers

Traditional infrastructure often began with physical servers – machines running a single operating system directly on the hardware. While straightforward initially, this approach has significant limitations in modern environments.

<Aside type="caution" title="Limitations of Raw Servers">
*   **Resource Underutilization**: Applications rarely use the full capacity of a dedicated server, leading to wasted resources.
*   **Difficult Scaling**: Adding capacity requires procuring, installing, and configuring new physical hardware, which is slow and expensive.
*   **Long Provisioning Time**: Setting up a new server with the correct OS, patches, and dependencies can take days or weeks.
*   **High Maintenance Costs**: Physical servers require space, power, cooling, and hands-on maintenance.
*   **Limited Isolation**: Applications running directly on the same OS can conflict (e.g., different library version requirements, resource contention).
</Aside>

### 2. Hypervisors & Virtual Machines (VMs)

To address the limitations of raw servers, hypervisors emerged in the early 2000s, enabling virtualization.

*   **Type 1 (Bare Metal)**: Run directly on the server hardware (e.g., VMware ESXi, Microsoft Hyper-V, KVM). They manage guest Virtual Machines directly.
*   **Type 2 (Hosted)**: Run on top of a conventional host operating system (e.g., VirtualBox, VMware Workstation/Fusion).

Hypervisors allow multiple Virtual Machines (VMs) to run concurrently on a single physical server. Each VM encapsulates an entire operating system (guest OS) along with the application and its dependencies.

**Benefits of VMs:**

*   Improved resource utilization through server consolidation.
*   Strong isolation between VMs, as each has its own OS kernel.
*   Faster provisioning compared to physical servers.

<Aside type="note" title="VM Drawbacks">
Despite the improvements, VMs still presented challenges:

*   **Resource Overhead**: Each VM requires a full guest OS installation (kernel, drivers, libraries), consuming significant disk space, RAM, and CPU resources even before the application runs.
*   **Slower Boot Times**: VMs take minutes to boot up their entire operating system.
*   **Size**: VM images are typically large (gigabytes).
*   **Limited Portability**: Moving VMs between different hypervisors or cloud environments can sometimes be complex.
</Aside>

### 3. Docker & Containers

Docker, introduced in 2013, popularized OS-level virtualization, known as containerization, addressing many VM limitations by using container technology:

*   **Shared Host OS Kernel**: Containers run as isolated processes on the host operating system, sharing its kernel. This eliminates the need for a separate guest OS per application.
*   **Lightweight & Fast**: Containers start almost instantly (seconds or less) because there's no OS to boot. They have minimal resource overhead.
*   **Efficient Resource Usage**: Significantly higher density – you can run many more containers than VMs on the same hardware due to the reduced overhead.
*   **Consistent Environments**: Package applications with all their dependencies (libraries, binaries, configuration files), ensuring they run uniformly across development, testing, and production environments.
*   **Strong Isolation**: Provides process-level isolation, keeping applications and their dependencies separate from each other and the host system.

Docker's key innovations simplified the use of containers:

*   **Dockerfile**: A text file defining the steps to build a container image.
*   **Standardized Image Format**: Created a widely adopted standard for packaging applications.
*   **Container Registries**: Hubs (like Docker Hub) for storing, sharing, and discovering container images.
*   **Developer Tooling**: A powerful command-line interface (CLI) and ecosystem for building, running, and managing containers.

## What are Containers?

Containers are lightweight, standalone, executable software packages that bundle everything needed to run an application: code, runtime (e.g., Node.js, Python), system tools, system libraries, and settings. They isolate the application from its environment, ensuring it runs consistently regardless of the underlying infrastructure ("It works on my machine" problems are greatly reduced).

### Docker Images vs Containers

Understanding the distinction between Docker images and containers is crucial for working with Docker effectively. Here's how they differ:

#### Docker Images
* A Docker image is a read-only template containing instructions for creating a container
* Think of it as a blueprint or snapshot of what will be in the container when it runs
* Images are immutable - once created, they cannot be changed
* Images are built in layers, with each layer representing a instruction in the Dockerfile
* Images can be shared and reused through registries like Docker Hub
* They contain all the necessary components to run an application: code, runtime, libraries, environment variables, and configuration files

#### Docker Containers
* A container is a runnable instance of a Docker image
* Think of it as a running process that executes the image's instructions
* Containers are mutable - they can be started, stopped, moved, and deleted
* Each container has its own writable layer for storing runtime data
* Multiple containers can be created from the same image, each running in isolation
* Containers only live as long as the process inside them is running

<Aside type="tip" title="Image vs Container Analogy">
Think of it like a cooking recipe:
* The **image** is like the recipe (instructions, ingredients list, etc.)
* The **container** is like the actual prepared dish (the result of following the recipe)
* You can make multiple dishes (containers) from the same recipe (image)
* Each dish (container) exists independently and can be modified without affecting the original recipe (image)
</Aside>

### Container vs. Virtual Machine (VM)

| Feature          | Containers                         | Virtual Machines (VMs)              |
| :--------------- | :--------------------------------- | :---------------------------------- |
| **Architecture** | Share host OS kernel               | Run complete guest OS + hypervisor  |
| **Size**         | Typically Megabytes (MB)           | Typically Gigabytes (GB)            |
| **Startup Time** | Seconds or milliseconds            | Minutes                             |
| **Performance**  | Near-native speed                  | Performance overhead due to hypervisor |
| **Isolation**    | Process-level isolation            | Full hardware virtualization isolation |
| **Resource Usage**| Minimal overhead (CPU, RAM, Disk) | Significant overhead (CPU, RAM, Disk)|
| **Portability**  | Highly portable across hosts      | Less portable, hypervisor-dependent |
| **Density**      | High (many containers per host)    | Lower (fewer VMs per host)          |

### Visual Comparison

#### Container Architecture

```text {title="Containers Share Host OS Kernel"}
┌─────────────────────────────────────────────────┐
│              Application A   Application B      │
│              (Binaries / Libs)                  │
├─────────────┬─────────────────┬─────────────────┤
│  Container  │    Container    │    Container    │
│      A      │        B        │        C        │
│  (Node.js)  │    (Redis)      │   (MongoDB)     │
├─────────────┴─────────────────┴─────────────────┤
│                Container Engine (e.g., Docker)  │
├─────────────────────────────────────────────────┤
│                   Host OS (Kernel)              │
├─────────────────────────────────────────────────┤
│                  Infrastructure (Hardware)      │
└─────────────────────────────────────────────────┘

Virtual Machine Architecture

┌───────────────┐  ┌───────────────┐  ┌───────────────┐
│  Application  │  │  Application  │  │  Application  │
│   (Binaries / Libs)   │   (Binaries / Libs)    │   (Binaries / Libs)   │
├───────────────┤  ├───────────────┤  ├───────────────┤
│ Guest OS (A)  │  │ Guest OS (B)  │  │ Guest OS (C)  │
├───────────────┤  ├───────────────┤  ├───────────────┤
│      VM A     │  │      VM B     │  │      VM C     │
├───────────────┴──┴───────────────┴──┴───────────────┤
│                   Hypervisor                        │
├─────────────────────────────────────────────────────┤
│                     Host OS (Optional)              │
├─────────────────────────────────────────────────────┤
│                    Infrastructure (Hardware)        │
└─────────────────────────────────────────────────────┘
```
{/* Ensure a blank line before the next component */}
<Aside type="note">
The core difference is the layer of abstraction. Containers virtualize the operating system, while VMs virtualize the underlying hardware.
</Aside>

## Docker Installation

Docker Desktop is the easiest way to get started on Windows and macOS, providing a graphical interface and managing necessary components. For Linux servers, Docker Engine is typically installed directly.

### Windows

<Steps>
  <ol>
    <li>
      **Download:** Get Docker Desktop for Windows from the official Docker Hub.
    </li>
    <li>
      **Install:** Run the downloaded installer (`Docker Desktop Installer.exe`). Follow the on-screen prompts. It will likely require enabling the WSL 2 (Windows Subsystem for Linux 2) feature, which is the recommended backend for performance. A system restart may be needed.
    </li>
    <li>
      **Launch:** Start Docker Desktop from the Windows Start Menu. Allow it a minute or two to initialize the Docker Engine.
    </li>
    <li>
      **Verify:** Open PowerShell or Command Prompt and run the command below. You should see the installed Docker version.
      ```bash
      docker --version
      ```
    </li>
  </ol>
</Steps>

### macOS

<Steps>
  <ol>
    <li>
      **Download:** Get Docker Desktop for Mac from the official Docker Hub. Make sure to download the correct version for your Mac (Apple Silicon or Intel).
    </li>
    <li>
      **Install:** Open the downloaded `.dmg` file and drag the Docker application icon into your Applications folder.
    </li>
    <li>
      **Launch:** Start Docker from your Applications folder. You might need to grant system permissions during the first launch.
    </li>
    <li>
      **Verify:** Open the Terminal application (`Applications/Utilities/Terminal.app`) and run the command below.
      ```bash
      docker --version
      ```
    </li>
  </ol>
</Steps>

### Ubuntu Linux (and similar Debian-based distros)

<Steps>
  <ol>
    <li>
      **Update and Install Prerequisites:** Update your package index and install packages needed to allow `apt` to use a repository over HTTPS:
      ```bash
      sudo apt update
      sudo apt install apt-transport-https ca-certificates curl software-properties-common -y
      ```
    </li>
    <li>
      **Add Docker's GPG Key:** Add Docker's official GPG key to ensure the authenticity of the packages:
      ```bash
      curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg
      ```
    </li>
    <li>
      **Set Up Stable Repository:** Add the Docker stable repository to your system's APT sources:
      ```bash
      echo \
        "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \
        $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
      ```
    </li>
    <li>
      **Install Docker Engine:** Update the package index again (now including the Docker repo) and install the latest version of Docker Engine, CLI, containerd, and Docker Compose plugin:
      ```bash
      sudo apt update
      sudo apt install docker-ce docker-ce-cli containerd.io docker-compose-plugin -y
      ```
    </li>
    <li>
      **Start and Enable Docker Service:** Ensure the Docker service starts automatically on boot:
      ```bash
      sudo systemctl start docker
      sudo systemctl enable docker
      ```
    </li>
    <li>
      **Verify Installation:** Check that Docker Engine is installed correctly by checking its version:
      ```bash
      docker --version
      ```
    </li>
  </ol>
</Steps>

### Post-Installation Steps (Linux Only)
Post-Installation Steps (Linux Only)
<Aside type="tip" title="Run Docker without `sudo`">
By default, Docker commands require root privileges. To run Docker commands as a non-root user, add your user to the `docker` group.
First, add your user to the docker group:
```bash
sudo usermod -aG docker ${USER}
```


Next, apply the group changes. You might need to log out and log back in for the changes to take effect, or run the following command in your current shell (this only affects the current shell session):
```bash
newgrp docker
```


</Aside>
Verify Installation (All Platforms)
A simple way to test if Docker is installed and running correctly is to run the hello-world container:
```bash
docker run hello-world
```

## Basic Docker Commands

Here are the essential Docker commands you'll need to work with images and containers effectively.

### Image Commands

<Steps>
  <ol>
    <li>
      **Pull an Image**
      ```bash
      docker pull <image-name>:<tag>
      ```
      Downloads an image from Docker Hub. If no tag is specified, it pulls the `latest` tag.
    </li>
    <li>
      **List Images**
      ```bash
      docker images
      # or
      docker image ls
      ```
      Shows all locally stored Docker images.
    </li>
    <li>
      **Remove Image**
      ```bash
      docker rmi <image-name>
      # or force remove
      docker rmi -f <image-name>
      ```
      Deletes an image from your local system.
    </li>
    <li>
      **Build Image**
      ```bash
      docker build -t <image-name>:<tag> .
      ```
      Builds a new image from a Dockerfile in the current directory.
    </li>
  </ol>
</Steps>

### Container Commands

<Steps>
  <ol>
    <li>
      **Run Container**
      ```bash
      docker run <image-name>
      # run in detached mode
      docker run -d <image-name>
      # run with port mapping
      docker run -p <host-port>:<container-port> <image-name>
      ```
      Creates and starts a new container from an image.
    </li>
    <li>
      **List Containers**
      ```bash
      # list running containers
      docker ps
      # list all containers (including stopped)
      docker ps -a
      ```
      Shows currently running containers or all containers.
    </li>
    <li>
      **Stop Container**
      ```bash
      docker stop <container-id/name>
      ```
      Gracefully stops a running container.
    </li>
    <li>
      **Remove Container**
      ```bash
      docker rm <container-id/name>
      # force remove running container
      docker rm -f <container-id/name>
      ```
      Removes a stopped container (or force removes a running container).
    </li>
  </ol>
</Steps>

### Utility Commands

<Steps>
  <ol>
    <li>
      **Container Logs**
      ```bash
      docker logs <container-id/name>
      # follow log output
      docker logs -f <container-id/name>
      ```
      View the logs of a container.
    </li>
    <li>
      **Execute Commands**
      ```bash
      docker exec -it <container-id/name> <command>
      # example: open a shell
      docker exec -it <container-id/name> bash
      ```
      Run a command in a running container.
    </li>
    <li>
      **Container Information**
      ```bash
      docker inspect <container-id/name>
      ```
      Shows detailed information about a container.
    </li>
    <li>
      **System Cleanup**
      ```bash
      # remove all stopped containers
      docker container prune
      # remove unused images
      docker image prune
      # remove all unused objects
      docker system prune
      ```
      Clean up unused Docker objects.
    </li>
  </ol>
</Steps>

<Aside type="tip" title="Working with Containers">
When working with containers, you can use either the container ID or the container name. Container IDs can be shortened to the first few unique characters. For example, if a container ID is `1234567890ab`, you can use just `1234` if it's unique enough to identify the container.
</Aside>

<Aside type="note" title="Container Names">
If you don't specify a name when running a container (using `--name`), Docker will generate a random name combining an adjective and a famous scientist/hacker's name, like `eager_einstein` or `focused_feynman`.
</Aside>
